### 如果你已经在完全相同的训练集上训练了5个不同的模型，并且它们都达到了95%的准确率，是否还有机会通过结合这些模型来获得更好的结果？如果可以，该怎么做？如果不行，为什么？

组合一个投票集成。
如果模型之间非常不同或训练实例也不同则效果更好。

### 硬投票分类器和软投票分类器有什么区别？

硬投票只是进行多票者得。软投票计算出每个类的平均估算概率，选出概率最高的类别。

### 是否可以通过在多个服务器上并行来加速bagging集成的训练？pasting集成呢？boosting集成呢？随机森林或stacking集成呢？

bagging由于使用有放回，所以可以进行分布式训练。pasting同理。
但boosting集成基于前序，所以必须有序进行无法并行。stacking中层与层之间需要有序。

### 包外评估的好处是什么？

包外评估可以对bagging集成中的每个预测器使用其未经训练的实例评估，不需要额外的验证集合，对集成的性能可以略有提升。

### 是什么让极端随机树比一般随机森林更加随机？这部分增加的随机性有什么用？极端随机树比一般随机森林快还是慢？

由于不需要计算最佳阈值，所以比一般随机森林更快。增加的随机性如同一种正则化，防止一般随机森林过拟合数据。

### 如果你的AdaBoost集成对训练数据欠拟合，你应该调整哪些超参数？怎么调整？

可以尝试增加估算器数量或者降低基础估计器的正则化参数。

### 如果你的梯度提升集成对训练集过拟合，你是应该提升还是降低学习率？

应该降低学习率
